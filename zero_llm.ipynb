{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e817be05-dde0-4f41-a772-4a25f7c95e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sentencepiece as spm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058c983f-ee5b-417e-b02a-6202321a75ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 1. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶èª­ã¿è¾¼ã¿ =====\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"tokenizer.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b71d8b-1e35-4a4c-80d6-53990f6fbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾© =====\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, block_size):\n",
    "        self.data = torch.tensor(sp.encode(text, out_type=int), dtype=torch.long)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(0, len(self.data) - self.block_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.block_size]\n",
    "        y = self.data[idx+1:idx+self.block_size+1]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6df0be0-9942-401b-be17-8c7de79d4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆæœ€å°GPTé¢¨ï¼‰ =====\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=128, n_layer=2, n_head=4, block_size=64):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_emb = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=n_embd, nhead=n_head),\n",
    "            num_layers=n_layer\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.size()\n",
    "        tok = self.tok_emb(idx)\n",
    "        pos = self.pos_emb(torch.arange(T, device=idx.device))\n",
    "        x = tok + pos\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf389b2-987c-4dec-9482-6a28081313d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 571\n",
      "len(dataset): 507\n"
     ]
    }
   ],
   "source": [
    "# ===== 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™ =====\n",
    "with open(\"data/input.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "block_size = 64\n",
    "dataset = TextDataset(text, block_size)\n",
    "print(f\"len(data): {len(dataset.data)}\")\n",
    "print(f\"len(dataset): {len(dataset)}\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f13ddde-1e4a-4c3a-834c-c788f08974c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh1/deepl/mynovel/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# ===== 5. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MiniGPT(vocab_size=sp.vocab_size(), block_size=block_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c1c1a-7da8-455e-b0ca-0cfbccfe417b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | loss: 5.5747\n",
      "Epoch 2/50 | loss: 4.2032\n",
      "Epoch 3/50 | loss: 2.8580\n",
      "Epoch 4/50 | loss: 1.9388\n",
      "Epoch 5/50 | loss: 1.4045\n",
      "Epoch 6/50 | loss: 1.1376\n",
      "Epoch 7/50 | loss: 1.0013\n",
      "Epoch 8/50 | loss: 0.9265\n",
      "Epoch 9/50 | loss: 0.8786\n",
      "Epoch 10/50 | loss: 0.8498\n",
      "Epoch 11/50 | loss: 0.8316\n",
      "Epoch 12/50 | loss: 0.8126\n",
      "Epoch 13/50 | loss: 0.8008\n",
      "Epoch 14/50 | loss: 0.7916\n",
      "Epoch 15/50 | loss: 0.7850\n",
      "Epoch 16/50 | loss: 0.7748\n",
      "Epoch 17/50 | loss: 0.7774\n",
      "Epoch 18/50 | loss: 0.7692\n",
      "Epoch 19/50 | loss: 0.7643\n",
      "Epoch 20/50 | loss: 0.7605\n",
      "Epoch 21/50 | loss: 0.7572\n",
      "Epoch 22/50 | loss: 0.7574\n",
      "Epoch 23/50 | loss: 0.7542\n",
      "Epoch 24/50 | loss: 0.7513\n",
      "Epoch 25/50 | loss: 0.7484\n",
      "Epoch 26/50 | loss: 0.7486\n",
      "Epoch 27/50 | loss: 0.7461\n",
      "Epoch 28/50 | loss: 0.7434\n",
      "Epoch 29/50 | loss: 0.7453\n",
      "Epoch 30/50 | loss: 0.7436\n",
      "Epoch 31/50 | loss: 0.7400\n",
      "Epoch 32/50 | loss: 0.7420\n",
      "Epoch 33/50 | loss: 0.7345\n",
      "Epoch 34/50 | loss: 0.7337\n",
      "Epoch 35/50 | loss: 0.7334\n",
      "Epoch 36/50 | loss: 0.7320\n",
      "Epoch 37/50 | loss: 0.7327\n",
      "Epoch 38/50 | loss: 0.7330\n",
      "Epoch 39/50 | loss: 0.7319\n",
      "Epoch 40/50 | loss: 0.7321\n",
      "Epoch 41/50 | loss: 0.7316\n",
      "Epoch 42/50 | loss: 0.7306\n",
      "Epoch 43/50 | loss: 0.7278\n",
      "Epoch 44/50 | loss: 0.7270\n",
      "Epoch 45/50 | loss: 0.7273\n",
      "Epoch 46/50 | loss: 0.7243\n",
      "Epoch 47/50 | loss: 0.7252\n",
      "Epoch 48/50 | loss: 0.7262\n",
      "Epoch 49/50 | loss: 0.7282\n",
      "Epoch 50/50 | loss: 0.7255\n"
     ]
    }
   ],
   "source": [
    "# ===== 6. å­¦ç¿’ãƒ«ãƒ¼ãƒ— =====\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, sp.vocab_size()), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56eb568f-e285-4e01-83a7-c29f9636cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ checkpoints/model_final.pth ã«ä¿å­˜ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# ===== 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ =====\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"checkpoints/model_final.pth\")\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ checkpoints/model_final.pth ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce628f89-7fc9-4ad1-9caa-8493562a9a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# ===== 8. ãƒ¢ãƒ‡ãƒ«å†èª­ã¿è¾¼ã¿ =====\n",
    "model.load_state_dict(torch.load(\"checkpoints/model_final.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078094e3-fdc9-45d0-a693-5c88a931ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 9. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆé–¢æ•° =====\n",
    "def generate_text(model, sp, start_text=\"ã“ã‚“ã«ã¡ã¯\", max_new_tokens=50):\n",
    "    model.eval()\n",
    "    ids = sp.encode(start_text, out_type=int)\n",
    "    x = torch.tensor(ids, dtype=torch.long, device=device)[None, :]\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(x)\n",
    "        next_id = torch.argmax(logits[0, -1]).item()\n",
    "        x = torch.cat([x, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return sp.decode(x[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d840334-c1fe-44b5-8c3d-37bd222be13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  ç”Ÿæˆçµæœ:\n",
      "AIã¯è‡ªç„¶è¨€èªå‡¦ç†ã§ãã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ æ¬¡ã®å˜èªã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ optimizer. optim\n"
     ]
    }
   ],
   "source": [
    "# ===== 10. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ =====\n",
    "generated = generate_text(model, sp, \"AIã¯\", 40)\n",
    "print(\"ğŸ§  ç”Ÿæˆçµæœ:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04383f-af3e-4324-bbc3-8be68ecdb6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
