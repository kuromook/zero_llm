{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e817be05-dde0-4f41-a772-4a25f7c95e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sentencepiece as spm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058c983f-ee5b-417e-b02a-6202321a75ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 1. ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶èª­ã¿è¾¼ã¿ =====\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"tokenizer.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b71d8b-1e35-4a4c-80d6-53990f6fbfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®šç¾© =====\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, block_size):\n",
    "        self.data = torch.tensor(sp.encode(text, out_type=int), dtype=torch.long)\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(0, len(self.data) - self.block_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.block_size]\n",
    "        y = self.data[idx+1:idx+self.block_size+1]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6df0be0-9942-401b-be17-8c7de79d4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3. ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆæœ€å°GPTé¢¨ï¼‰ =====\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd=128, n_layer=2, n_head=4, block_size=64):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_emb = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=n_embd, nhead=n_head),\n",
    "            num_layers=n_layer\n",
    "        )\n",
    "        self.ln = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        B, T = idx.size()\n",
    "        tok = self.tok_emb(idx)\n",
    "        pos = self.pos_emb(torch.arange(T, device=idx.device))\n",
    "        x = tok + pos\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccf389b2-987c-4dec-9482-6a28081313d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 571\n",
      "len(dataset): 507\n"
     ]
    }
   ],
   "source": [
    "# ===== 4. ãƒ‡ãƒ¼ã‚¿æº–å‚™ =====\n",
    "with open(\"data/input.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "block_size = 64\n",
    "dataset = TextDataset(text, block_size)\n",
    "print(f\"len(data): {len(dataset.data)}\")\n",
    "print(f\"len(dataset): {len(dataset)}\")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f13ddde-1e4a-4c3a-834c-c788f08974c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh1/deepl/mynovel/venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# ===== 5. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– =====\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MiniGPT(vocab_size=sp.vocab_size(), block_size=block_size).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c1c1a-7da8-455e-b0ca-0cfbccfe417b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | loss: 5.5381\n",
      "Epoch 2/50 | loss: 4.0828\n",
      "Epoch 3/50 | loss: 2.7771\n",
      "Epoch 4/50 | loss: 1.8913\n",
      "Epoch 5/50 | loss: 1.3795\n",
      "Epoch 6/50 | loss: 1.1226\n",
      "Epoch 7/50 | loss: 0.9905\n",
      "Epoch 8/50 | loss: 0.9201\n",
      "Epoch 9/50 | loss: 0.8780\n",
      "Epoch 10/50 | loss: 0.8448\n",
      "Epoch 11/50 | loss: 0.8272\n",
      "Epoch 12/50 | loss: 0.8110\n",
      "Epoch 13/50 | loss: 0.7995\n",
      "Epoch 14/50 | loss: 0.7924\n",
      "Epoch 15/50 | loss: 0.7826\n",
      "Epoch 16/50 | loss: 0.7782\n",
      "Epoch 17/50 | loss: 0.7722\n",
      "Epoch 18/50 | loss: 0.7691\n",
      "Epoch 19/50 | loss: 0.7668\n",
      "Epoch 20/50 | loss: 0.7624\n",
      "Epoch 21/50 | loss: 0.7576\n",
      "Epoch 22/50 | loss: 0.7558\n",
      "Epoch 23/50 | loss: 0.7496\n",
      "Epoch 24/50 | loss: 0.7494\n",
      "Epoch 25/50 | loss: 0.7473\n",
      "Epoch 26/50 | loss: 0.7445\n",
      "Epoch 27/50 | loss: 0.7463\n",
      "Epoch 28/50 | loss: 0.7423\n",
      "Epoch 29/50 | loss: 0.7385\n",
      "Epoch 30/50 | loss: 0.7394\n",
      "Epoch 31/50 | loss: 0.7430\n",
      "Epoch 32/50 | loss: 0.7381\n",
      "Epoch 33/50 | loss: 0.7362\n",
      "Epoch 34/50 | loss: 0.7347\n",
      "Epoch 35/50 | loss: 0.7363\n",
      "Epoch 36/50 | loss: 0.7354\n",
      "Epoch 37/50 | loss: 0.7321\n",
      "Epoch 38/50 | loss: 0.7322\n",
      "Epoch 39/50 | loss: 0.7355\n",
      "Epoch 40/50 | loss: 0.7336\n",
      "Epoch 41/50 | loss: 0.7345\n",
      "Epoch 42/50 | loss: 0.7268\n",
      "Epoch 43/50 | loss: 0.7285\n",
      "Epoch 44/50 | loss: 0.7277\n",
      "Epoch 45/50 | loss: 0.7263\n",
      "Epoch 46/50 | loss: 0.7275\n",
      "Epoch 47/50 | loss: 0.7258\n",
      "Epoch 48/50 | loss: 0.7252\n",
      "Epoch 49/50 | loss: 0.7298\n",
      "Epoch 50/50 | loss: 0.7287\n"
     ]
    }
   ],
   "source": [
    "# ===== 6. å­¦ç¿’ãƒ«ãƒ¼ãƒ— =====\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, sp.vocab_size()), y.view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | loss: {total_loss/len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56eb568f-e285-4e01-83a7-c29f9636cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ checkpoints/model_final.pth ã«ä¿å­˜ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# ===== 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜ =====\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"checkpoints/model_final.pth\")\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ checkpoints/model_final.pth ã«ä¿å­˜ã—ã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce628f89-7fc9-4ad1-9caa-8493562a9a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ\n"
     ]
    }
   ],
   "source": [
    "# ===== 8. ãƒ¢ãƒ‡ãƒ«å†èª­ã¿è¾¼ã¿ =====\n",
    "model.load_state_dict(torch.load(\"checkpoints/model_final.pth\", map_location=device))\n",
    "model.eval()\n",
    "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’å†èª­ã¿è¾¼ã¿ã—ã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14837d0c-5569-45b2-b400-68b993ada52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 9. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆé–¢æ•° =====\n",
    "def generate_text(model, sp, start_text=\"ã“ã‚“ã«ã¡ã¯\", max_new_tokens=50):\n",
    "    model.eval()\n",
    "    ids = sp.encode(start_text, out_type=int)\n",
    "    x = torch.tensor(ids, dtype=torch.long, device=device)[None, :]\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(x)\n",
    "        next_id = torch.argmax(logits[0, -1]).item()\n",
    "        x = torch.cat([x, torch.tensor([[next_id]], device=device)], dim=1)\n",
    "    return sp.decode(x[0].tolist())\n",
    "\n",
    "\n",
    "# ===== 10. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ =====\n",
    "generated = generate_text(model, sp, \"AIã¯\", 40)\n",
    "print(\"ğŸ§  ç”Ÿæˆçµæœ:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f04383f-af3e-4324-bbc3-8be68ecdb6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  ç”Ÿæˆçµæœ:\n",
      "AIã¯å­¦ç¿’ç”¨ç¢ºå˜æ¥å§‹ å¤œãˆã‚ˆã¯å¯æ¬¡ã®å˜èªã‚’å­¦ç¿’ã™ãªå­¦ç¿’ã—ã¾ã™ ãƒ‡æ˜nã‚’ä½¿ã†ãƒ€æ–°ã—ã„ã§ã™ã€‚ ç°¡å‡º ç°¡in ç°¡ã—ã¾ã™ã„ã¤ã“ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€ç¾ã—ã„çŸ¥ã€\n"
     ]
    }
   ],
   "source": [
    "# ===== 9' ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³) ==\n",
    "import random\n",
    "\n",
    "\n",
    "def generate_text(model, sp, prompt, max_new_tokens=50, temperature=1.0, top_p=0.9, repetition_penalty=1.2):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    tokens = torch.tensor(sp.encode(prompt), dtype=torch.long).unsqueeze(0).to(device)\n",
    "    generated = tokens.clone()\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        with torch.no_grad():\n",
    "            logits = model(tokens)[:, -1, :] / temperature\n",
    "\n",
    "            # ğŸ”¹ ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£\n",
    "            for token_id in set(generated[0].tolist()):\n",
    "                logits[0, token_id] /= repetition_penalty\n",
    "\n",
    "            # ğŸ”¹ softmaxï¼ˆå®‰å…¨ç‰ˆï¼‰\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs = torch.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            # ğŸ”¹ nucleus (top-p) ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå®‰å…¨å‡¦ç†ä»˜ãï¼‰\n",
    "            sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "            cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "            # top-p ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°\n",
    "            sorted_probs[cumulative_probs > top_p] = 0.0\n",
    "\n",
    "            # æ­£è¦åŒ–å‰ã«ãƒã‚§ãƒƒã‚¯\n",
    "            sum_probs = sorted_probs.sum()\n",
    "            if sum_probs == 0 or torch.isnan(sum_probs):\n",
    "                # fallback: å‡ä¸€åˆ†å¸ƒã«ã™ã‚‹ï¼ˆå®‰å…¨ç­–ï¼‰\n",
    "                sorted_probs = torch.ones_like(sorted_probs) / sorted_probs.numel()\n",
    "            else:\n",
    "                sorted_probs /= sum_probs\n",
    "\n",
    "            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "            next_token = torch.multinomial(sorted_probs, 1)\n",
    "            next_token = sorted_indices[0, next_token.item()].view(1, 1)\n",
    "\n",
    "            # ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ›´æ–°\n",
    "            tokens = torch.cat([tokens, next_token], dim=1)\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "\n",
    "            # ğŸ”¹ çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ãªã‚‰åœæ­¢\n",
    "            if next_token.item() == sp.eos_id():\n",
    "                break\n",
    "\n",
    "    return sp.decode(generated[0].tolist())\n",
    "\n",
    "generated = generate_text(model, sp, \"AIã¯\", 40)\n",
    "print(\"ğŸ§  ç”Ÿæˆçµæœ:\")\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe1bb4-5214-4699-9e26-1fa244671fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
